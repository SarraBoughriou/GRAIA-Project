{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install tensorflow\n",
    "!pip install codecarbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "\n",
    "trackerTot= EmissionsTracker()\n",
    "trackerTot.start()\n",
    "\n",
    "tracker= EmissionsTracker()\n",
    "tracker.start()\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels)  = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Print shapes of training and testing data\n",
    "print('Training data shape : ', train_images.shape, train_labels.shape)\n",
    "print('Testing data shape : ', test_images.shape, test_labels.shape)\n",
    "\n",
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(train_labels)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)\n",
    "\n",
    "# Display the first image in training and testing data\n",
    "plt.figure(figsize=[4,2])\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_images[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(train_labels[0]))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(test_images[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(test_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to check if an image is black\n",
    "def is_black(image, threshold=10):\n",
    "    # Compute the average pixel intensity\n",
    "    avg_intensity = np.mean(image)\n",
    "    # Return True if the average intensity is below the threshold, indicating a \"black\" image\n",
    "    return avg_intensity < threshold\n",
    "\n",
    "# Define a function to iterate through images and check for blackness\n",
    "def check_black(images, threshold=10):\n",
    "    black_indices = []\n",
    "    for i, image in enumerate(images):\n",
    "        if is_black(image, threshold):\n",
    "            black_indices.append(i)\n",
    "    return black_indices\n",
    "\n",
    "# Function to display images with their indices\n",
    "def display_images_with_indices(images, indices):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    num_images = len(indices)\n",
    "    for i, idx in enumerate(indices):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(images[idx])\n",
    "        plt.title(f\"Index: {idx}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Check for black images\n",
    "black_indices = check_black(train_images)\n",
    "\n",
    "# Print the number of black images\n",
    "print(\"Number of black images:\", len(black_indices))\n",
    "\n",
    "# Display the black images along with their indices\n",
    "display_images_with_indices(train_images, black_indices)\n",
    "\n",
    "\n",
    "# Remove blurry images from the dataset using their indices\n",
    "train_images = np.delete(train_images, black_indices, axis=0)\n",
    "train_labels = np.delete(train_labels, black_indices, axis=0)\n",
    "\n",
    "# Print the shape of the cleaned dataset\n",
    "print(\"Shape of cleaned dataset:\", train_images.shape, train_labels.shape)\n",
    "print(\"Black images deleted.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape and preprocess the training and testing data\n",
    "nRows,nCols,nDims = train_images.shape[1:]\n",
    "train_data = train_images.reshape(train_images.shape[0], nRows, nCols, nDims)\n",
    "test_data = test_images.reshape(test_images.shape[0], nRows, nCols, nDims)\n",
    "input_shape = (nRows, nCols, nDims)\n",
    "\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    "\n",
    "train_data /= 255\n",
    "test_data /= 255\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "datagen.fit(train_images)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "train_labels_one_hot = to_categorical(train_labels)\n",
    "test_labels_one_hot = to_categorical(test_labels)\n",
    "\n",
    "print('Original label 0 : ', train_labels[0])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot[0])\n",
    "\n",
    "print(\"Shape of final dataset:\", train_data.shape, train_labels.shape)\n",
    "\n",
    "\n",
    "emissions: float = tracker.stop()\n",
    "print(f\"PreProcessing Emissions:{emissions} Kg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 model\n",
    "def build_vgg16(input_shape=(32, 32, 3), num_classes=10):\n",
    "    model = models.Sequential()\n",
    "    # Block 1\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 4\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 5\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Classifier\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))  # Add dropout for regularization\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))  # Add dropout for regularization\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build the VGG16 model\n",
    "model = build_vgg16()\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "optimizer = optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-4\n",
    "    if epoch > 75:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 50:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 25:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 10:\n",
    "        lr *= 1e-1\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "tracker= EmissionsTracker()\n",
    "tracker.start()\n",
    "\n",
    "# Train the model with data augmentation\n",
    "history = model.fit(datagen.flow(train_images, train_labels_one_hot, batch_size=128),\n",
    "                    epochs=200,\n",
    "                    validation_data=(test_images, test_labels_one_hot),\n",
    "                    callbacks=[lr_scheduler, early_stopping])\n",
    "emissions: float = tracker.stop()\n",
    "print(f\"Training Emissions:{emissions} Kg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker= EmissionsTracker()\n",
    "tracker.start()\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels_one_hot, verbose=2)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "emissions: float = tracker.stop()\n",
    "print(f\"Testing Emissions:{emissions} Kg\")\n",
    "print('**************')\n",
    "emissionsTot: float = trackerTot.stop()\n",
    "print(f\"Total Emissions:{emissionsTot} Kg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
