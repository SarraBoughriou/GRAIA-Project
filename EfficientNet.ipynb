{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12939985",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install tensorflow\n",
    "!pip install codecarbon\n",
    "!pip install opencv-python pandas numpy tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b09bfe5-12ad-4d25-a799-7b93d916c64b",
   "metadata": {},
   "outputs": [],
   "source": [
    " import os, time, pathlib, math, random\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    " \n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "import cv2\n",
    "\n",
    "from codecarbon import EmissionsTracker\n",
    " \n",
    "# ---------- Config ----------\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    " \n",
    "ROOT = Path(\".\")\n",
    "\n",
    "RESULTS_CSV = ROOT / \"results.csv\"\n",
    "\n",
    "LOGDIR = (ROOT / \"codecarbon_logs\").resolve()\n",
    "\n",
    "LOGDIR.mkdir(parents=True, exist_ok=True)\n",
    " \n",
    "CODECARBON_KWARGS = dict(\n",
    "\n",
    "    measure_power_secs=1,\n",
    "\n",
    "    save_to_file=True,\n",
    "\n",
    "    output_dir=str(LOGDIR),\n",
    "\n",
    "    log_level=\"warning\",\n",
    "\n",
    "    tracking_mode=\"process\",  \n",
    "\n",
    ")\n",
    " \n",
    "print(f\"[CodeCarbon] logs → {LOGDIR}\")\n",
    " \n",
    "\n",
    "def is_blurry(image, threshold=100):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Returns True if image is blurry based on Laplacian variance.\n",
    "\n",
    "    CIFAR-10 is RGB, so use COLOR_RGB2GRAY.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    variance = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "\n",
    "    return variance < threshold\n",
    " \n",
    "def check_blur(images, threshold=100):\n",
    "\n",
    "    blurry_images = []\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "\n",
    "        if is_blurry(image, threshold):\n",
    "\n",
    "            blurry_images.append(i)\n",
    "\n",
    "    return blurry_images\n",
    " \n",
    "def is_black(image, threshold=10):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Returns True if image is near-black.\n",
    "\n",
    "    Threshold is the mean pixel intensity (0-255 scale).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    return float(np.mean(image)) < threshold\n",
    " \n",
    "def check_black(images, threshold=10):\n",
    "\n",
    "    black_indices = []\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "\n",
    "        if is_black(image, threshold):\n",
    "\n",
    "            black_indices.append(i)\n",
    "\n",
    "    return black_indices\n",
    " \n",
    "def display_images_with_indices(images, indices, cols=8, title=\"Selected images\"):\n",
    "\n",
    "    if len(indices) == 0:\n",
    "\n",
    "        print(\"[display] No images to display.\")\n",
    "\n",
    "        return\n",
    "\n",
    "    rows = int(math.ceil(len(indices) / cols))\n",
    "\n",
    "    plt.figure(figsize=(cols*2, rows*2))\n",
    "\n",
    "    for i, idx in enumerate(indices[: rows*cols]):\n",
    "\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "\n",
    "        plt.imshow(images[idx])\n",
    "\n",
    "        plt.title(f\"idx={idx}\", fontsize=8)\n",
    "\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    plt.show()\n",
    " \n",
    "# ---------- Phase helpers ----------\n",
    "\n",
    "def run_with_tracker(phase_name, fn):\n",
    "\n",
    "    tracker = EmissionsTracker(project_name=phase_name, **CODECARBON_KWARGS)\n",
    "\n",
    "    tracker.start()\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    try:\n",
    "\n",
    "        out = fn()\n",
    "\n",
    "    finally:\n",
    "\n",
    "        emissions = tracker.stop() or 0.0\n",
    "\n",
    "    secs = time.time() - t0\n",
    "\n",
    "    print(f\"[{phase_name}] time={secs:.2f}s  emissions={emissions:.6f} kg\")\n",
    "\n",
    "    return out, secs, emissions\n",
    " \n",
    "# ============================================\n",
    "\n",
    "# 1) PREPROCESS PHASE\n",
    "\n",
    "# ============================================\n",
    "\n",
    "def preprocess_phase():\n",
    "\n",
    "    # Load CIFAR-10\n",
    "\n",
    "    (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "    print('Training data shape : ', train_images.shape, train_labels.shape)\n",
    "\n",
    "    print('Testing  data shape : ', test_images.shape,  test_labels.shape)\n",
    "\n",
    "    classes = np.unique(train_labels)\n",
    "\n",
    "    nClasses = len(classes)\n",
    "\n",
    "    print('Total number of outputs : ', nClasses)\n",
    "\n",
    "    print('Output classes : ', classes.reshape(-1))\n",
    " \n",
    "    # Clean: remove blurry & black from TRAIN \n",
    "\n",
    "    BLUR_THR  = 100.0\n",
    "\n",
    "    BLACK_THR = 10.0\n",
    " \n",
    "    blurry_idx = check_blur(train_images, threshold=BLUR_THR)\n",
    "\n",
    "    black_idx  = check_black(train_images, threshold=BLACK_THR)\n",
    "\n",
    "    print(f\"Found blurry={len(blurry_idx)}  black={len(black_idx)} in train\")\n",
    " \n",
    "\n",
    "    to_remove = sorted(set(blurry_idx) | set(black_idx))\n",
    "\n",
    "    if to_remove:\n",
    "\n",
    "        keep_mask = np.ones(len(train_images), dtype=bool)\n",
    "\n",
    "        keep_mask[to_remove] = False\n",
    "\n",
    "        train_images = train_images[keep_mask]\n",
    "\n",
    "        train_labels = train_labels[keep_mask]\n",
    "\n",
    "        print(f\"Removed {len(to_remove)} images → train now {train_images.shape}\")\n",
    " \n",
    "    # Scale to [0,1]\n",
    "\n",
    "    train_images = train_images.astype(\"float32\") / 255.0\n",
    "\n",
    "    test_images  = test_images.astype(\"float32\")  / 255.0\n",
    " \n",
    "    # One-hot labels\n",
    "\n",
    "    y_train = to_categorical(train_labels, nClasses)\n",
    "\n",
    "    y_test  = to_categorical(test_labels,  nClasses)\n",
    " \n",
    "    # Augmentation (light)\n",
    "\n",
    "    aug = ImageDataGenerator(\n",
    "\n",
    "        horizontal_flip=True,\n",
    "\n",
    "    )\n",
    "\n",
    "    aug.fit(train_images)\n",
    " \n",
    "    return (train_images, y_train), (test_images, y_test), nClasses, aug\n",
    " \n",
    "(prep_out, preprocess_secs, preprocess_em) = run_with_tracker(\"preprocess\", preprocess_phase)\n",
    "\n",
    "print(\" fin preprocessing\")\n",
    "\n",
    "(train_images, y_train), (test_images, y_test), nClasses, aug = prep_out\n",
    " \n",
    "# ============================================\n",
    "\n",
    "# 2) BUILD + TRAIN PHASE (Keras Sequential CNN)\n",
    "\n",
    "# ============================================\n",
    "\n",
    "def train_phase():\n",
    "\n",
    "    model = Sequential([\n",
    "\n",
    "        Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(32,32,3), padding=\"same\"),\n",
    "\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "        Dropout(0.25),\n",
    " \n",
    "        Conv2D(64, kernel_size=(3,3), activation='relu', padding=\"same\"),\n",
    "\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "        Dropout(0.25),\n",
    " \n",
    "        Conv2D(128, kernel_size=(3,3), activation='relu', padding=\"same\"),\n",
    "\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "        Dropout(0.25),\n",
    " \n",
    "        Flatten(),\n",
    "\n",
    "        Dense(256, activation='relu'),\n",
    "\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(nClasses, activation='softmax')\n",
    "\n",
    "    ])\n",
    " \n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "\n",
    "                  loss='categorical_crossentropy',\n",
    "\n",
    "                  metrics=['accuracy'])\n",
    " \n",
    "    BATCH = 64\n",
    "\n",
    "    EPOCHS = 50\n",
    " \n",
    "    # Use augmented batches for training; evaluate on clean test\n",
    "\n",
    "    history = model.fit(\n",
    "\n",
    "        aug.flow(train_images, y_train, batch_size=BATCH, shuffle=True),\n",
    "\n",
    "        epochs=EPOCHS,\n",
    "\n",
    "        validation_data=(test_images, y_test),\n",
    "\n",
    "        verbose=1\n",
    "\n",
    "    )\n",
    "\n",
    "    params = model.count_params()\n",
    "\n",
    "    return model, params, history.history\n",
    " \n",
    "((model, params, history), train_secs, train_em) = run_with_tracker(\"train\", train_phase)\n",
    " \n",
    "# ============================================\n",
    "\n",
    "# 3) EVALUATION PHASE\n",
    "\n",
    "# ============================================\n",
    "\n",
    "def eval_phase():\n",
    "\n",
    "    loss, acc = model.evaluate(test_images, y_test, verbose=0)\n",
    "\n",
    "    print(f\"Test accuracy: {acc:.4f}\")\n",
    "\n",
    "    return float(acc)\n",
    " \n",
    "(test_acc, eval_secs, eval_em) = run_with_tracker(\"evaluate\", eval_phase)\n",
    " \n",
    "# ============================================\n",
    "\n",
    "# 4) Save / append results\n",
    "\n",
    "# ============================================\n",
    "\n",
    "row = {\n",
    "\n",
    "    \"model\": \"Keras-Sequential-CNN(clean:blur+black + flip aug)\",\n",
    "\n",
    "    \"params\": params,\n",
    "\n",
    "    \"test_acc\": round(test_acc, 4),\n",
    "\n",
    "    \"preprocess_secs\": round(preprocess_secs, 2),\n",
    "\n",
    "    \"train_secs\": round(train_secs, 2),\n",
    "\n",
    "    \"eval_secs\": round(eval_secs, 2),\n",
    "\n",
    "    \"preprocess_emissions_kg\": preprocess_em,\n",
    "\n",
    "    \"train_emissions_kg\": train_em,\n",
    "\n",
    "    \"eval_emissions_kg\": eval_em,\n",
    "\n",
    "    \"total_secs\": round(preprocess_secs + train_secs + eval_secs, 2),\n",
    "\n",
    "    \"total_emissions_kg\": preprocess_em + train_em + eval_em,\n",
    "\n",
    "}\n",
    "\n",
    "df_new = pd.DataFrame([row])\n",
    " \n",
    "if RESULTS_CSV.exists():\n",
    "\n",
    "    try:\n",
    "\n",
    "        df_old = pd.read_csv(RESULTS_CSV)\n",
    "\n",
    "        df_out = pd.concat([df_old, df_new], ignore_index=True)\n",
    "\n",
    "    except Exception:\n",
    "\n",
    "        df_out = df_new\n",
    "\n",
    "else:\n",
    "\n",
    "    df_out = df_new\n",
    " \n",
    "df_out.to_csv(RESULTS_CSV, index=False)\n",
    "\n",
    "print(\"Appended results →\", RESULTS_CSV.resolve())\n",
    "\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556e1631-dac5-45d3-b560-e40c5f96c1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
